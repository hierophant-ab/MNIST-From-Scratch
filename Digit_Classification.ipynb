{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"mnist_train.csv\")\n",
    "df_test=pd.read_csv(\"mnist_test.csv\")\n",
    "\n",
    "#Training dataset Input and labels\n",
    "Y=np.array(df[\"label\"])\n",
    "X=np.array(df.loc[0:,\"1x1\":])\n",
    "X=X.T\n",
    "X=X/255\n",
    "\n",
    "#Test dataset Input and Labels\n",
    "Y_test=np.array(df_test[\"label\"])\n",
    "X_test=np.array(df_test.loc[0:,\"1x1\":])\n",
    "X_test=X_test.T\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y,m):\n",
    "    Y_hotCoded=np.zeros((10,m)).T\n",
    "    Y_hotCoded[range(m),Y]=1\n",
    "    Y_hotCoded=Y_hotCoded.T\n",
    "\n",
    "    return Y_hotCoded\n",
    "\n",
    "Y_hotCoded=one_hot(Y,Y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_parameters(X):\n",
    "    n_x=X.shape[0]\n",
    "\n",
    "    W1=np.random.randn(512,n_x)*0.01\n",
    "    b1=np.zeros((512,1))\n",
    "    W2=np.random.randn(256,512)*0.01\n",
    "    b2=np.zeros((256,1))\n",
    "    W3=np.random.randn(10,256)*0.01\n",
    "    b3=np.zeros((10,1))\n",
    "\n",
    "\n",
    "    parameters={\"W1\":W1,\n",
    "                \"b1\":b1,\n",
    "                \"W2\":W2,\n",
    "                \"b2\":b2,\n",
    "                \"W3\":W3,\n",
    "                \"b3\":b3}\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    A=np.maximum(0,x)\n",
    "\n",
    "    return A\n",
    "\n",
    "def derive_relu(x):\n",
    "    return x>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_activation(x):\n",
    "    x=x-x.max(axis=0)\n",
    "    x_e=np.exp(x)\n",
    "    x_summed=np.sum(x_e,axis=0,keepdims=True)\n",
    "    A=x_e/x_summed\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    W3=parameters[\"W3\"]\n",
    "    b3=parameters[\"b3\"]\n",
    "\n",
    "\n",
    "    Z1=W1@X+b1\n",
    "    A1=relu(Z1)\n",
    "    Z2=W2@A1+b2\n",
    "    A2=relu(Z2)\n",
    "    Z3=W3@A2+b3\n",
    "    A3=softmax_activation(Z3)\n",
    "\n",
    "    cache={\"Z1\":Z1,\n",
    "    \"A1\":A1,\"Z2\":Z2,\"A2\":A2,\"Z3\":Z3,\"A3\":A3}\n",
    "\n",
    "    return A3,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(Y,A3):\n",
    "    m=A3.shape[1]\n",
    "    A3=A3.T\n",
    "    A3=np.clip(A3,1e-7,1-1e-7)\n",
    "    confidences=A3[range(m),Y]\n",
    "    log_likelihood=-np.log(confidences)\n",
    "    cost=np.mean(log_likelihood)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X,Y,parameters,cache):\n",
    "    m=X.shape[1]\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    W3=parameters[\"W3\"]\n",
    "    b3=parameters[\"b3\"]\n",
    "\n",
    "    Z1=cache[\"Z1\"]\n",
    "    A1=cache[\"A1\"]\n",
    "    Z2=cache[\"Z2\"]\n",
    "    A2=cache[\"A2\"]\n",
    "    Z3=cache[\"Z3\"]\n",
    "    A3=cache[\"A3\"]\n",
    "\n",
    "    dZ3=A3-Y\n",
    "    dW3=1/m*dZ3@(A2.T)\n",
    "    db3=1/m*np.sum(dZ3,axis=1,keepdims=True)\n",
    "    dZ2=W3.T@dZ3*(derive_relu(Z2))\n",
    "    dW2=1/m*dZ2@A1.T\n",
    "    db2=1/m*np.sum(dZ2,axis=1,keepdims=True)\n",
    "    dZ1=W2.T@dZ2*(derive_relu(Z1))\n",
    "    dW1=1/m*dZ1@X.T\n",
    "    db1=1/m*np.sum(dZ1,axis=1,keepdims=True)\n",
    "\n",
    "\n",
    "    gradient={\"dW1\":dW1,\n",
    "              \"db1\":db1,\n",
    "              \"dW2\":dW2,\n",
    "              \"db2\":db2,\n",
    "              \"dW3\":dW3,\n",
    "              \"db3\":db3}\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters,gradient,alpha=0.4):\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    W3=parameters[\"W3\"]\n",
    "    b3=parameters[\"b3\"]\n",
    "    \n",
    "\n",
    "    dW1=gradient[\"dW1\"]\n",
    "    db1=gradient[\"db1\"]\n",
    "    dW2=gradient[\"dW2\"]\n",
    "    db2=gradient[\"db2\"]\n",
    "    dW3=gradient[\"dW3\"]\n",
    "    db3=gradient[\"db3\"]\n",
    "\n",
    "    W1=W1-alpha*dW1\n",
    "    W2=W2-alpha*dW2\n",
    "    W3=W3-alpha*dW3\n",
    "    b1=b1-alpha*db1\n",
    "    b2=b2-alpha*db2\n",
    "    b3=b3-alpha*db3\n",
    "\n",
    "    parameters={\"W1\":W1,\n",
    "                \"b1\":b1,\n",
    "                \"W2\":W2,\n",
    "                \"b2\":b2,\n",
    "                \"W3\":W3,\n",
    "                \"b3\":b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,parameters):\n",
    "    A2,cache=forward_propagation(X,parameters)\n",
    "    prediction=np.argmax(A2,axis=0)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def accuracy(prediction,Y):\n",
    "    return float(np.sum(Y==prediction)/Y.size*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,Y_hotCoded,iterations=1000):\n",
    "    parameters=initiate_parameters(X)\n",
    "    cost=0\n",
    "    for i in range(iterations):\n",
    "        A2,cache=forward_propagation(X,parameters)\n",
    "        cost=calculate_cost(Y,A2)\n",
    "        gradient=backward_propagation(X,Y_hotCoded,parameters,cache)\n",
    "        parameters=update_parameters(parameters,gradient)\n",
    "\n",
    "    return float(cost),parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_GD(X,Y,num_epochs=15):\n",
    "    parameters=initiate_parameters(X)\n",
    "    X=X.T\n",
    "    cost=[]\n",
    "    accuracy_=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        indices = np.random.permutation(len(X))\n",
    "        X_train_shuffled = X[indices]\n",
    "        y_train_shuffled = Y[indices]\n",
    "        batch_size=100\n",
    "        cost_epoch=0\n",
    "        \n",
    "        for i in range(0, len(X), batch_size):\n",
    "            X_batch = X_train_shuffled[i:i+batch_size].T\n",
    "            y_batch = y_train_shuffled[i:i+batch_size]\n",
    "            Y_hotCoded=one_hot(y_batch,y_batch.shape[0])\n",
    "\n",
    "            A2,cache=forward_propagation(X_batch,parameters)\n",
    "            cost_epoch=calculate_cost(y_batch,A2)\n",
    "            gradient=backward_propagation(X_batch,Y_hotCoded,parameters,cache)\n",
    "            parameters=update_parameters(parameters,gradient)\n",
    "\n",
    "        cost.append(float(cost_epoch))\n",
    "        prediction=predict(X.T,parameters)\n",
    "        accuracy_.append(accuracy(prediction,Y))\n",
    "\n",
    "    return cost,parameters,accuracy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost,parameters,accuracy_=mini_batch_GD(X,Y)\n",
    "pred_prob_test=forward_propagation(X_test,parameters)[0].T\n",
    "print(cost[-1],accuracy_[-1])\n",
    "\n",
    "\n",
    "prediction_test=predict(X_test,parameters)\n",
    "accuracy(prediction_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=confusion_matrix(Y,predict(X,parameters))\n",
    "cr_train=classification_report(Y,predict(X,parameters))\n",
    "\n",
    "cm_test=confusion_matrix(Y_test,prediction_test)\n",
    "cr_test=classification_report(Y_test,prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_auc(y_true, y_pred, classes):\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    aucs = np.array([roc_auc_score(y_true_bin[:, i], y_pred[:, i]) for i in range(len(classes))])\n",
    "    return np.round(aucs,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_curves(y_true, y_score, classes, title):\n",
    "    y_true_bin = label_binarize(y_true, classes=classes)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for i, color in zip(range(len(classes)), cycle(['aqua','darkorange','cornflowerblue','green'])):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {classes[i]} (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0,1], [0,1], 'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aucs=np.array(per_class_auc(Y_test,pred_prob_test,classes=range(10)))\n",
    "print(f\"Neural Network AUCs: {aucs}\")\n",
    "plot_roc_curves(Y_test,pred_prob_test,classes=range(10),title=\"Neural Network ROC- Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "n=624\n",
    "pixels=X_test.T[n].reshape(28,28)\n",
    "pixels_uint8 = (pixels * 255).astype(np.uint8)\n",
    "img = Image.fromarray(pixels_uint8, mode='L')  # 'L' mode is for grayscale\n",
    "print(prediction_test[n])\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
